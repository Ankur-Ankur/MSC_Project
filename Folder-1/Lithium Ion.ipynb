{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efac008a-5d23-4052-8c27-dfa125403593",
   "metadata": {},
   "source": [
    "# Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d56b1e61-35bf-421b-bea0-18f1be4828a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Imports and basic config\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2f2f26-c9c9-470f-ab58-682c49f09bf0",
   "metadata": {},
   "source": [
    "# Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d487838-6945-423a-8f83-b008afdc92df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Paths and config\n",
    "\n",
    "DATA_DIR = r\"D:\\Work\\November\\26 Nov\\job 1\\dataset\"   # <-- change this to your folder\n",
    "FILE_PATTERN = os.path.join(DATA_DIR, \"*.xlsx\")\n",
    "\n",
    "EARLY_CYCLE_MAX = 20   # how many early cycles to use as input\n",
    "TEST_SIZE = 0.2\n",
    "VAL_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398f27d1-4073-430f-b468-5e544fa075b2",
   "metadata": {},
   "source": [
    "# Helper: Load One File and Clean Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "255f32ce-8a19-467f-bae2-ebb7557f477b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_battery_file(filepath):\n",
    "    \"\"\"\n",
    "    Load a single Excel file and return a cleaned DataFrame\n",
    "    with an added battery_id column.\n",
    "    \"\"\"\n",
    "    df = pd.read_excel(filepath)\n",
    "    \n",
    "    # Ensure columns are exactly as expected (rename if needed)\n",
    "    expected_cols = [\n",
    "        \"Data_Point\", \"Test_Time(s)\", \"Current(A)\", \"Capacity(Ah)\",\n",
    "        \"Voltage(V)\", \"Energy(Wh)\", \"Temperature(℃)\", \"Date_Time\", \"Cycle_Index\"\n",
    "    ]\n",
    "    \n",
    "    # Optional: check and adapt if names slightly differ\n",
    "    # For now, assume they match\n",
    "    \n",
    "    # Add battery_id from filename\n",
    "    battery_id = os.path.splitext(os.path.basename(filepath))[0]\n",
    "    df[\"battery_id\"] = battery_id\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8410ffbe-a1fb-4419-9b96-5b49bd905659",
   "metadata": {},
   "source": [
    "# Load All Files and Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89eadfbc-e648-46e0-bd0c-eb994cccfb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded files: ['D:\\\\Work\\\\November\\\\26 Nov\\\\job 1\\\\dataset\\\\LR1865SZ_cycles201228_001_1.xlsx', 'D:\\\\Work\\\\November\\\\26 Nov\\\\job 1\\\\dataset\\\\LR1865SZ_cycles210109_001_1.xlsx', 'D:\\\\Work\\\\November\\\\26 Nov\\\\job 1\\\\dataset\\\\LR1865SZ_cycles210121_001_1.xlsx', 'D:\\\\Work\\\\November\\\\26 Nov\\\\job 1\\\\dataset\\\\LR1865SZ_cycles210121_001_2.xlsx']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_Point</th>\n",
       "      <th>Test_Time(s)</th>\n",
       "      <th>Current(A)</th>\n",
       "      <th>Capacity(Ah)</th>\n",
       "      <th>Voltage(V)</th>\n",
       "      <th>Energy(Wh)</th>\n",
       "      <th>Temperature(℃)</th>\n",
       "      <th>Date_Time</th>\n",
       "      <th>Cycle_Index</th>\n",
       "      <th>battery_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.1887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.74</td>\n",
       "      <td>2020-12-28 14:47:00</td>\n",
       "      <td>1</td>\n",
       "      <td>LR1865SZ_cycles201228_001_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>00:00:01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.1887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.74</td>\n",
       "      <td>2020-12-28 14:47:02</td>\n",
       "      <td>1</td>\n",
       "      <td>LR1865SZ_cycles201228_001_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>00:00:02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.1887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.74</td>\n",
       "      <td>2020-12-28 14:47:03</td>\n",
       "      <td>1</td>\n",
       "      <td>LR1865SZ_cycles201228_001_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>00:00:03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.1887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.74</td>\n",
       "      <td>2020-12-28 14:47:04</td>\n",
       "      <td>1</td>\n",
       "      <td>LR1865SZ_cycles201228_001_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>00:00:05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.1881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.74</td>\n",
       "      <td>2020-12-28 14:47:05</td>\n",
       "      <td>1</td>\n",
       "      <td>LR1865SZ_cycles201228_001_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data_Point Test_Time(s)  Current(A)  Capacity(Ah)  Voltage(V)  Energy(Wh)  \\\n",
       "0           1     00:00:00         0.0           0.0      4.1887         0.0   \n",
       "1           2     00:00:01         0.0           0.0      4.1887         0.0   \n",
       "2           3     00:00:02         0.0           0.0      4.1887         0.0   \n",
       "3           4     00:00:03         0.0           0.0      4.1887         0.0   \n",
       "4           5     00:00:05         0.0           0.0      4.1881         0.0   \n",
       "\n",
       "   Temperature(℃)           Date_Time  Cycle_Index  \\\n",
       "0           26.74 2020-12-28 14:47:00            1   \n",
       "1           26.74 2020-12-28 14:47:02            1   \n",
       "2           26.74 2020-12-28 14:47:03            1   \n",
       "3           26.74 2020-12-28 14:47:04            1   \n",
       "4           26.74 2020-12-28 14:47:05            1   \n",
       "\n",
       "                    battery_id  \n",
       "0  LR1865SZ_cycles201228_001_1  \n",
       "1  LR1865SZ_cycles201228_001_1  \n",
       "2  LR1865SZ_cycles201228_001_1  \n",
       "3  LR1865SZ_cycles201228_001_1  \n",
       "4  LR1865SZ_cycles201228_001_1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR = r\"D:\\Work\\November\\26 Nov\\job 1\\dataset\"\n",
    "FILE_PATTERN = os.path.join(DATA_DIR, \"*.xlsx\")\n",
    "\n",
    "all_files = [f for f in glob.glob(FILE_PATTERN)\n",
    "             if not os.path.basename(f).startswith(\"~$\")]\n",
    "\n",
    "print(\"Loaded files:\", all_files)\n",
    "\n",
    "def load_battery_file(filepath):\n",
    "    df = pd.read_excel(filepath)\n",
    "    df[\"battery_id\"] = os.path.splitext(os.path.basename(filepath))[0]\n",
    "    return df\n",
    "\n",
    "df_list = [load_battery_file(f) for f in all_files]\n",
    "full_df = pd.concat(df_list, ignore_index=True)\n",
    "full_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1120f56-785d-4118-be8f-7cdc23b8326e",
   "metadata": {},
   "source": [
    "# Build Cycle-Level Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ceb709b6-2013-414f-9fdb-82213005ae09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_id</th>\n",
       "      <th>Cycle_Index</th>\n",
       "      <th>Current(A)_mean</th>\n",
       "      <th>Current(A)_max</th>\n",
       "      <th>Current(A)_min</th>\n",
       "      <th>Capacity(Ah)_last</th>\n",
       "      <th>Capacity(Ah)_max</th>\n",
       "      <th>Voltage(V)_mean</th>\n",
       "      <th>Voltage(V)_max</th>\n",
       "      <th>Voltage(V)_min</th>\n",
       "      <th>Energy(Wh)_mean</th>\n",
       "      <th>Temperature(℃)_mean</th>\n",
       "      <th>Temperature(℃)_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR1865SZ_cycles201228_001_1</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.697573</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-7.212</td>\n",
       "      <td>2.252</td>\n",
       "      <td>2.252</td>\n",
       "      <td>3.611645</td>\n",
       "      <td>4.1899</td>\n",
       "      <td>3.0001</td>\n",
       "      <td>4.022060</td>\n",
       "      <td>34.669455</td>\n",
       "      <td>43.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR1865SZ_cycles201228_001_1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.022133</td>\n",
       "      <td>4.809</td>\n",
       "      <td>-7.209</td>\n",
       "      <td>1.699</td>\n",
       "      <td>1.699</td>\n",
       "      <td>3.761866</td>\n",
       "      <td>4.2005</td>\n",
       "      <td>3.0001</td>\n",
       "      <td>3.872848</td>\n",
       "      <td>33.203625</td>\n",
       "      <td>41.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LR1865SZ_cycles201228_001_1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.008003</td>\n",
       "      <td>4.809</td>\n",
       "      <td>-7.212</td>\n",
       "      <td>1.680</td>\n",
       "      <td>1.684</td>\n",
       "      <td>3.760497</td>\n",
       "      <td>4.2001</td>\n",
       "      <td>3.0001</td>\n",
       "      <td>3.863702</td>\n",
       "      <td>33.083700</td>\n",
       "      <td>41.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LR1865SZ_cycles201228_001_1</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.037121</td>\n",
       "      <td>4.809</td>\n",
       "      <td>-7.212</td>\n",
       "      <td>1.665</td>\n",
       "      <td>1.672</td>\n",
       "      <td>3.758351</td>\n",
       "      <td>4.2001</td>\n",
       "      <td>3.0001</td>\n",
       "      <td>3.847844</td>\n",
       "      <td>33.121772</td>\n",
       "      <td>41.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR1865SZ_cycles201228_001_1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.004399</td>\n",
       "      <td>4.809</td>\n",
       "      <td>-7.212</td>\n",
       "      <td>1.651</td>\n",
       "      <td>1.657</td>\n",
       "      <td>3.760258</td>\n",
       "      <td>4.2001</td>\n",
       "      <td>2.9998</td>\n",
       "      <td>3.819075</td>\n",
       "      <td>33.028073</td>\n",
       "      <td>41.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    battery_id  Cycle_Index  Current(A)_mean  Current(A)_max  \\\n",
       "0  LR1865SZ_cycles201228_001_1            1        -4.697573           0.000   \n",
       "1  LR1865SZ_cycles201228_001_1            2        -0.022133           4.809   \n",
       "2  LR1865SZ_cycles201228_001_1            3        -0.008003           4.809   \n",
       "3  LR1865SZ_cycles201228_001_1            4        -0.037121           4.809   \n",
       "4  LR1865SZ_cycles201228_001_1            5        -0.004399           4.809   \n",
       "\n",
       "   Current(A)_min  Capacity(Ah)_last  Capacity(Ah)_max  Voltage(V)_mean  \\\n",
       "0          -7.212              2.252             2.252         3.611645   \n",
       "1          -7.209              1.699             1.699         3.761866   \n",
       "2          -7.212              1.680             1.684         3.760497   \n",
       "3          -7.212              1.665             1.672         3.758351   \n",
       "4          -7.212              1.651             1.657         3.760258   \n",
       "\n",
       "   Voltage(V)_max  Voltage(V)_min  Energy(Wh)_mean  Temperature(℃)_mean  \\\n",
       "0          4.1899          3.0001         4.022060            34.669455   \n",
       "1          4.2005          3.0001         3.872848            33.203625   \n",
       "2          4.2001          3.0001         3.863702            33.083700   \n",
       "3          4.2001          3.0001         3.847844            33.121772   \n",
       "4          4.2001          2.9998         3.819075            33.028073   \n",
       "\n",
       "   Temperature(℃)_max  \n",
       "0               43.14  \n",
       "1               41.32  \n",
       "2               41.93  \n",
       "3               41.32  \n",
       "4               41.32  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_cycle_features(full_df):\n",
    "    grouped = full_df.groupby([\"battery_id\", \"Cycle_Index\"])\n",
    "    features = grouped.agg({\n",
    "        \"Current(A)\": [\"mean\", \"max\", \"min\"],\n",
    "        \"Capacity(Ah)\": [\"last\", \"max\"],\n",
    "        \"Voltage(V)\": [\"mean\", \"max\", \"min\"],\n",
    "        \"Energy(Wh)\": [\"mean\"],\n",
    "        \"Temperature(℃)\": [\"mean\", \"max\"]\n",
    "    })\n",
    "    features.columns = [\"_\".join(col).strip() for col in features.columns]\n",
    "    return features.reset_index()\n",
    "\n",
    "cycle_df = build_cycle_features(full_df)\n",
    "cycle_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfe42d4-5655-4a50-b854-92423d91bc67",
   "metadata": {},
   "source": [
    "# Build Categorical Life Label (Short / Medium / Long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11def7ca-a514-43e3-9c6d-123ac95997d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    battery_id  target_EOL_cycle\n",
      "0  LR1865SZ_cycles201228_001_1                 2\n",
      "1  LR1865SZ_cycles210109_001_1                 2\n",
      "2  LR1865SZ_cycles210121_001_1                12\n",
      "3  LR1865SZ_cycles210121_001_2                12\n"
     ]
    }
   ],
   "source": [
    "def build_targets_from_capacity(cycle_df, cap_ratio=0.8):\n",
    "    \"\"\"\n",
    "    EoL is defined as the first cycle where capacity <= cap_ratio * initial capacity.\n",
    "    If no such cycle exists, use max Cycle_Index.\n",
    "    Returns: battery_id, target_EOL_cycle\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for bid, grp in cycle_df.groupby(\"battery_id\"):\n",
    "        grp = grp.sort_values(\"Cycle_Index\")\n",
    "\n",
    "        # initial capacity = first cycle's capacity\n",
    "        initial_cap = grp[\"Capacity(Ah)_last\"].iloc[0]\n",
    "        threshold = cap_ratio * initial_cap\n",
    "\n",
    "        # find first cycle where capacity <= threshold\n",
    "        eol_cycles = grp.loc[grp[\"Capacity(Ah)_last\"] <= threshold, \"Cycle_Index\"]\n",
    "\n",
    "        if len(eol_cycles) > 0:\n",
    "            eol_cycle = int(eol_cycles.iloc[0])\n",
    "        else:\n",
    "            # fallback: use last recorded cycle\n",
    "            eol_cycle = int(grp[\"Cycle_Index\"].max())\n",
    "\n",
    "        rows.append({\"battery_id\": bid, \"target_EOL_cycle\": eol_cycle})\n",
    "\n",
    "    target_df = pd.DataFrame(rows)\n",
    "    return target_df\n",
    "\n",
    "target_df = build_targets_from_capacity(cycle_df, cap_ratio=0.8)\n",
    "print(target_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9209e2dd-f24f-4d8d-b1f5-7dd3515968ca",
   "metadata": {},
   "source": [
    "# Create Early-Cycle Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5701bf11-ecad-4eac-a6e3-f594f0de3460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    battery_id  target_EOL_cycle  life_class\n",
      "0  LR1865SZ_cycles201228_001_1                 2           0\n",
      "1  LR1865SZ_cycles210109_001_1                 2           0\n",
      "2  LR1865SZ_cycles210121_001_1                12           2\n",
      "3  LR1865SZ_cycles210121_001_2                12           2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def add_life_classes(target_df, n_classes=3):\n",
    "    \"\"\"\n",
    "    Add a categorical 'life_class' column based on quantiles of target_EOL_cycle.\n",
    "    \"\"\"\n",
    "    if len(target_df) < n_classes:\n",
    "        print(\"⚠ Not enough batteries for\", n_classes, \"classes. Using 2 classes instead.\")\n",
    "        n_classes = 2\n",
    "\n",
    "    if target_df[\"target_EOL_cycle\"].nunique() == 1:\n",
    "        print(\"⚠ All batteries still have identical EoL cycles. Only one class possible.\")\n",
    "        target_df[\"life_class\"] = 0\n",
    "        return target_df\n",
    "\n",
    "    quantiles = np.linspace(0, 1, n_classes + 1)\n",
    "    q_values = target_df[\"target_EOL_cycle\"].quantile(quantiles).values\n",
    "\n",
    "    # ensure strictly increasing\n",
    "    for i in range(1, len(q_values)):\n",
    "        if q_values[i] <= q_values[i-1]:\n",
    "            q_values[i] = q_values[i-1] + 1e-6\n",
    "\n",
    "    bins = q_values\n",
    "    labels = list(range(n_classes))\n",
    "\n",
    "    target_df[\"life_class\"] = pd.cut(\n",
    "        target_df[\"target_EOL_cycle\"],\n",
    "        bins=bins,\n",
    "        labels=labels,\n",
    "        include_lowest=True\n",
    "    ).astype(int)\n",
    "\n",
    "    return target_df\n",
    "\n",
    "target_df = add_life_classes(target_df, n_classes=3)\n",
    "print(target_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3eab24ff-7ad6-4cd3-8d76-e83b52f15f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (4, 20, 11)\n",
      "y: [0 0 2 2]\n",
      "Classes: [0 2]\n"
     ]
    }
   ],
   "source": [
    "EARLY_CYCLE_MAX = 20\n",
    "\n",
    "def create_sequences_categorical(cycle_df, target_df, early_cycle_max):\n",
    "    merged = cycle_df.merge(target_df, on=\"battery_id\", how=\"inner\")\n",
    "\n",
    "    X_list, y_list, ids = [], [], []\n",
    "\n",
    "    drop_cols = [\"battery_id\", \"Cycle_Index\", \"target_EOL_cycle\", \"life_class\"]\n",
    "    feature_cols = [c for c in merged.columns if c not in drop_cols]\n",
    "\n",
    "    for bid, sub in merged.groupby(\"battery_id\"):\n",
    "        sub = sub.sort_values(\"Cycle_Index\")\n",
    "\n",
    "        early = sub[sub[\"Cycle_Index\"] <= early_cycle_max]\n",
    "        if early.shape[0] < early_cycle_max:\n",
    "            continue\n",
    "\n",
    "        X_list.append(early[feature_cols].values)\n",
    "        y_list.append(int(early[\"life_class\"].iloc[0]))\n",
    "        ids.append(bid)\n",
    "\n",
    "    X = np.array(X_list)\n",
    "    y = np.array(y_list, dtype=int)\n",
    "    ids = np.array(ids)\n",
    "\n",
    "    return X, y, ids, feature_cols\n",
    "\n",
    "X, y, battery_ids, feature_cols = create_sequences_categorical(\n",
    "    cycle_df, target_df, EARLY_CYCLE_MAX\n",
    ")\n",
    "\n",
    "print(\"X:\", X.shape)\n",
    "print(\"y:\", y)\n",
    "print(\"Classes:\", np.unique(y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a047bc48-bd43-4291-9744-3d3179320cd6",
   "metadata": {},
   "source": [
    "# Train/Validation/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d78801d-9146-4dc1-bbb8-6919f44bd441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (4, 2, 11)\n",
      "y: [0 0 2 2]\n",
      "battery_ids: ['LR1865SZ_cycles201228_001_1' 'LR1865SZ_cycles210109_001_1'\n",
      " 'LR1865SZ_cycles210121_001_1' 'LR1865SZ_cycles210121_001_2']\n",
      "Classes in y: [0 2]\n",
      "Num features: 11\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "EARLY_CYCLE_MAX = 2  # use first 2 cycles as input for all batteries\n",
    "\n",
    "def create_early_cycle_sequences(cycle_df, target_df, early_cycle_max):\n",
    "    \"\"\"\n",
    "    Create early-cycle sequences (X) and categorical labels (y) per battery.\n",
    "    \n",
    "    X shape: (num_batteries, early_cycle_max, num_features)\n",
    "    y shape: (num_batteries,)  -> life_class (int)\n",
    "    \"\"\"\n",
    "    # Merge cycle-level features with target labels\n",
    "    merged = cycle_df.merge(target_df, on=\"battery_id\", how=\"inner\")\n",
    "    \n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    battery_ids = []\n",
    "    \n",
    "    # Features = all numeric columns except IDs and targets\n",
    "    drop_cols = [\"battery_id\", \"Cycle_Index\", \"target_EOL_cycle\", \"life_class\"]\n",
    "    feature_cols = [c for c in merged.columns if c not in drop_cols]\n",
    "    \n",
    "    for bid, sub in merged.groupby(\"battery_id\"):\n",
    "        # sort by cycle index to keep temporal order\n",
    "        sub = sub.sort_values(\"Cycle_Index\")\n",
    "        \n",
    "        # select early cycles only\n",
    "        early = sub[sub[\"Cycle_Index\"] <= early_cycle_max]\n",
    "        \n",
    "        # if a battery has fewer cycles than early_cycle_max, skip it\n",
    "        if early.shape[0] < early_cycle_max:\n",
    "            print(f\"Skipping {bid}: only {early.shape[0]} cycles available.\")\n",
    "            continue\n",
    "        \n",
    "        # sequence of shape (early_cycle_max, num_features)\n",
    "        seq = early[feature_cols].values\n",
    "        \n",
    "        X_list.append(seq)\n",
    "        y_list.append(int(early[\"life_class\"].iloc[0]))  # same class for all cycles of that battery\n",
    "        battery_ids.append(bid)\n",
    "    \n",
    "    if len(X_list) == 0:\n",
    "        raise ValueError(\"No batteries had enough early cycles. Reduce EARLY_CYCLE_MAX.\")\n",
    "    \n",
    "    X = np.array(X_list)\n",
    "    y = np.array(y_list, dtype=int)\n",
    "    battery_ids = np.array(battery_ids)\n",
    "    \n",
    "    return X, y, battery_ids, feature_cols\n",
    "\n",
    "X, y, battery_ids, feature_cols = create_early_cycle_sequences(\n",
    "    cycle_df, target_df, EARLY_CYCLE_MAX\n",
    ")\n",
    "\n",
    "print(\"X shape:\", X.shape)           # (num_batteries, early_cycle_max, num_features)\n",
    "print(\"y:\", y)                       # class labels\n",
    "print(\"battery_ids:\", battery_ids)   # which batteries used\n",
    "print(\"Classes in y:\", np.unique(y))\n",
    "print(\"Num features:\", len(feature_cols))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752051cc-dccf-4f8f-8dc1-e9a20c8a1b9f",
   "metadata": {},
   "source": [
    "# STEP 6 — Feature Scaling (same scaler over all timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f71501c1-8fe8-4960-af94-2fe52182ccfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class mapping: {0: 0, 2: 1}\n",
      "Original y: [0 0 2 2]\n",
      "Encoded y: [0 0 1 1]\n",
      "Encoded classes: [0 1]\n",
      "Total samples (batteries): 4\n",
      "⚠ Not enough batteries for a proper split. Using all data for train/val/test.\n",
      "Train shape: (4, 2, 11) (4,)\n",
      "Val shape:   (4, 2, 11) (4,)\n",
      "Test shape:  (4, 2, 11) (4,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 5.0 Remap classes from [0,2] -> [0,1]\n",
    "unique_classes = np.unique(y)\n",
    "class_to_idx = {c: i for i, c in enumerate(unique_classes)}\n",
    "print(\"Class mapping:\", class_to_idx)\n",
    "\n",
    "y_enc = np.array([class_to_idx[c] for c in y])  # encoded labels\n",
    "\n",
    "print(\"Original y:\", y)\n",
    "print(\"Encoded y:\", y_enc)\n",
    "print(\"Encoded classes:\", np.unique(y_enc))\n",
    "\n",
    "# 5.1 Train/Val/Test split\n",
    "n_samples = X.shape[0]\n",
    "print(\"Total samples (batteries):\", n_samples)\n",
    "\n",
    "if n_samples >= 8:\n",
    "    # Normal case (for larger dataset)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y_enc, test_size=0.2, random_state=42, shuffle=True, stratify=y_enc\n",
    "    )\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.25, random_state=42, shuffle=True, stratify=y_train\n",
    "    )\n",
    "else:\n",
    "    # Small dataset fallback: use everything for all splits\n",
    "    print(\"⚠ Not enough batteries for a proper split. Using all data for train/val/test.\")\n",
    "    X_train, y_train = X, y_enc\n",
    "    X_val,   y_val   = X, y_enc\n",
    "    X_test,  y_test  = X, y_enc\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Val shape:  \", X_val.shape,   y_val.shape)\n",
    "print(\"Test shape: \", X_test.shape,  y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4249f556-2f5c-4502-a16a-afda65f3f3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled shapes: (4, 2, 11) (4, 2, 11) (4, 2, 11)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Shapes\n",
    "num_train, T, F = X_train.shape\n",
    "num_val  = X_val.shape[0]\n",
    "num_test = X_test.shape[0]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Flatten time dimension\n",
    "X_train_flat = X_train.reshape(-1, F)\n",
    "X_val_flat   = X_val.reshape(-1, F)\n",
    "X_test_flat  = X_test.reshape(-1, F)\n",
    "\n",
    "# Fit on train only\n",
    "scaler.fit(X_train_flat)\n",
    "\n",
    "# Transform\n",
    "X_train_scaled = scaler.transform(X_train_flat).reshape(num_train, T, F)\n",
    "X_val_scaled   = scaler.transform(X_val_flat).reshape(num_val,   T, F)\n",
    "X_test_scaled  = scaler.transform(X_test_flat).reshape(num_test, T, F)\n",
    "\n",
    "X_train = X_train_scaled\n",
    "X_val   = X_val_scaled\n",
    "X_test  = X_test_scaled\n",
    "\n",
    "print(\"Scaled shapes:\", X_train.shape, X_val.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c9b879-65e0-4c87-ab8c-5bbf9dffd57d",
   "metadata": {},
   "source": [
    "# STEP 7 — Build & Train LSTM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e4fe056-6c15-43d9-ba0d-3ccc4d7822c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\masking.py:48: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ masking_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">19,456</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ masking_2 (\u001b[38;5;33mMasking\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m11\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m19,456\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │              \u001b[38;5;34m66\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,602</span> (84.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,602\u001b[0m (84.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,602</span> (84.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,602\u001b[0m (84.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 328ms/step - accuracy: 0.5000 - loss: 0.7277 - val_accuracy: 0.5000 - val_loss: 0.6927\n",
      "Epoch 2/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.2500 - loss: 0.7016 - val_accuracy: 0.7500 - val_loss: 0.6676\n",
      "Epoch 3/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.6457 - val_accuracy: 1.0000 - val_loss: 0.6440\n",
      "Epoch 4/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.7500 - loss: 0.6438 - val_accuracy: 1.0000 - val_loss: 0.6214\n",
      "Epoch 5/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.5799 - val_accuracy: 1.0000 - val_loss: 0.5986\n",
      "Epoch 6/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 0.5927 - val_accuracy: 1.0000 - val_loss: 0.5752\n",
      "Epoch 7/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 0.5731 - val_accuracy: 1.0000 - val_loss: 0.5515\n",
      "Epoch 8/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 0.5521 - val_accuracy: 1.0000 - val_loss: 0.5285\n",
      "Epoch 9/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.5106 - val_accuracy: 1.0000 - val_loss: 0.5066\n",
      "Epoch 10/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.5225 - val_accuracy: 1.0000 - val_loss: 0.4850\n",
      "Epoch 11/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.4568 - val_accuracy: 1.0000 - val_loss: 0.4641\n",
      "Epoch 12/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.4638 - val_accuracy: 1.0000 - val_loss: 0.4430\n",
      "Epoch 13/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 0.4548 - val_accuracy: 1.0000 - val_loss: 0.4217\n",
      "Epoch 14/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 0.3998 - val_accuracy: 1.0000 - val_loss: 0.4002\n",
      "Epoch 15/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 0.3965 - val_accuracy: 1.0000 - val_loss: 0.3787\n",
      "Epoch 16/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 0.3841 - val_accuracy: 1.0000 - val_loss: 0.3570\n",
      "Epoch 17/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 0.3581 - val_accuracy: 1.0000 - val_loss: 0.3350\n",
      "Epoch 18/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.3414 - val_accuracy: 1.0000 - val_loss: 0.3133\n",
      "Epoch 19/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 1.0000 - loss: 0.2940 - val_accuracy: 1.0000 - val_loss: 0.2919\n",
      "Epoch 20/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 0.3096 - val_accuracy: 1.0000 - val_loss: 0.2710\n",
      "Epoch 21/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 0.2903 - val_accuracy: 1.0000 - val_loss: 0.2505\n",
      "Epoch 22/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 1.0000 - loss: 0.2504 - val_accuracy: 1.0000 - val_loss: 0.2305\n",
      "Epoch 23/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 1.0000 - loss: 0.2310 - val_accuracy: 1.0000 - val_loss: 0.2110\n",
      "Epoch 24/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 1.0000 - loss: 0.2031 - val_accuracy: 1.0000 - val_loss: 0.1921\n",
      "Epoch 25/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 0.1882 - val_accuracy: 1.0000 - val_loss: 0.1742\n",
      "Epoch 26/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.1683 - val_accuracy: 1.0000 - val_loss: 0.1572\n",
      "Epoch 27/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.1478 - val_accuracy: 1.0000 - val_loss: 0.1415\n",
      "Epoch 28/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.1848 - val_accuracy: 1.0000 - val_loss: 0.1269\n",
      "Epoch 29/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.1164 - val_accuracy: 1.0000 - val_loss: 0.1134\n",
      "Epoch 30/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0969 - val_accuracy: 1.0000 - val_loss: 0.1012\n",
      "Epoch 31/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 0.1510 - val_accuracy: 1.0000 - val_loss: 0.0901\n",
      "Epoch 32/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 1.0000 - loss: 0.1011 - val_accuracy: 1.0000 - val_loss: 0.0799\n",
      "Epoch 33/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 1.0000 - loss: 0.0661 - val_accuracy: 1.0000 - val_loss: 0.0710\n",
      "Epoch 34/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0681 - val_accuracy: 1.0000 - val_loss: 0.0631\n",
      "Epoch 35/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0698 - val_accuracy: 1.0000 - val_loss: 0.0561\n",
      "Epoch 36/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 1.0000 - loss: 0.0689 - val_accuracy: 1.0000 - val_loss: 0.0499\n",
      "Epoch 37/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 0.0655 - val_accuracy: 1.0000 - val_loss: 0.0445\n",
      "Epoch 38/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.0514 - val_accuracy: 1.0000 - val_loss: 0.0397\n",
      "Epoch 39/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 1.0000 - loss: 0.0423 - val_accuracy: 1.0000 - val_loss: 0.0355\n",
      "Epoch 40/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0459 - val_accuracy: 1.0000 - val_loss: 0.0318\n",
      "Epoch 41/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0427 - val_accuracy: 1.0000 - val_loss: 0.0285\n",
      "Epoch 42/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 0.0394 - val_accuracy: 1.0000 - val_loss: 0.0257\n",
      "Epoch 43/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0227 - val_accuracy: 1.0000 - val_loss: 0.0232\n",
      "Epoch 44/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0320 - val_accuracy: 1.0000 - val_loss: 0.0210\n",
      "Epoch 45/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.0236 - val_accuracy: 1.0000 - val_loss: 0.0191\n",
      "Epoch 46/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0148 - val_accuracy: 1.0000 - val_loss: 0.0174\n",
      "Epoch 47/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.0205 - val_accuracy: 1.0000 - val_loss: 0.0160\n",
      "Epoch 48/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0181 - val_accuracy: 1.0000 - val_loss: 0.0147\n",
      "Epoch 49/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0139 - val_accuracy: 1.0000 - val_loss: 0.0136\n",
      "Epoch 50/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0130 - val_accuracy: 1.0000 - val_loss: 0.0127\n",
      "Epoch 51/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.0124 - val_accuracy: 1.0000 - val_loss: 0.0118\n",
      "Epoch 52/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0115 - val_accuracy: 1.0000 - val_loss: 0.0111\n",
      "Epoch 53/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 0.0221 - val_accuracy: 1.0000 - val_loss: 0.0104\n",
      "Epoch 54/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 0.0140 - val_accuracy: 1.0000 - val_loss: 0.0097\n",
      "Epoch 55/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0195 - val_accuracy: 1.0000 - val_loss: 0.0091\n",
      "Epoch 56/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - accuracy: 1.0000 - loss: 0.0095 - val_accuracy: 1.0000 - val_loss: 0.0085\n",
      "Epoch 57/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 0.0099 - val_accuracy: 1.0000 - val_loss: 0.0080\n",
      "Epoch 58/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 0.0099 - val_accuracy: 1.0000 - val_loss: 0.0075\n",
      "Epoch 59/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 1.0000 - val_loss: 0.0071\n",
      "Epoch 60/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0087 - val_accuracy: 1.0000 - val_loss: 0.0068\n",
      "Epoch 61/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.0119 - val_accuracy: 1.0000 - val_loss: 0.0064\n",
      "Epoch 62/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0128 - val_accuracy: 1.0000 - val_loss: 0.0061\n",
      "Epoch 63/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.0141 - val_accuracy: 1.0000 - val_loss: 0.0057\n",
      "Epoch 64/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 1.0000 - val_loss: 0.0054\n",
      "Epoch 65/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0102 - val_accuracy: 1.0000 - val_loss: 0.0052\n",
      "Epoch 66/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 1.0000 - val_loss: 0.0049\n",
      "Epoch 67/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 1.0000 - val_loss: 0.0047\n",
      "Epoch 68/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 1.0000 - val_loss: 0.0045\n",
      "Epoch 69/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 1.0000 - val_loss: 0.0043\n",
      "Epoch 70/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 1.0000 - val_loss: 0.0041\n",
      "Epoch 71/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.0112 - val_accuracy: 1.0000 - val_loss: 0.0039\n",
      "Epoch 72/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 0.0038\n",
      "Epoch 73/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
      "Epoch 74/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 1.0000 - val_loss: 0.0035\n",
      "Epoch 75/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
      "Epoch 76/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0098 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
      "Epoch 77/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 1.0000 - val_loss: 0.0031\n",
      "Epoch 78/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 0.0030\n",
      "Epoch 79/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 0.0029\n",
      "Epoch 80/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 0.0028\n",
      "Epoch 81/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 0.0027\n",
      "Epoch 82/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 0.0026\n",
      "Epoch 83/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 1.0000 - val_loss: 0.0025\n",
      "Epoch 84/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 0.0025\n",
      "Epoch 85/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 0.0024\n",
      "Epoch 86/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 1.0000 - val_loss: 0.0023\n",
      "Epoch 87/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 0.0023\n",
      "Epoch 88/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 0.0022\n",
      "Epoch 89/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 1.0000 - val_loss: 0.0022\n",
      "Epoch 90/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 0.0021\n",
      "Epoch 91/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 1.0000 - val_loss: 0.0021\n",
      "Epoch 92/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 0.0020\n",
      "Epoch 93/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 0.0020\n",
      "Epoch 94/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 0.0019\n",
      "Epoch 95/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 0.0019\n",
      "Epoch 96/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 0.0018\n",
      "Epoch 97/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 1.0000 - val_loss: 0.0018\n",
      "Epoch 98/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
      "Epoch 99/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
      "Epoch 100/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
      "Epoch 101/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
      "Epoch 102/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
      "Epoch 103/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
      "Epoch 104/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 105/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 106/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 107/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 108/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 109/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 8.7699e-04 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 110/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 111/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
      "Epoch 112/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
      "Epoch 113/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
      "Epoch 114/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
      "Epoch 115/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 116/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 117/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 118/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 119/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 6.2882e-04 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 120/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 121/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 122/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 123/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
      "Epoch 124/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 8.6303e-04 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
      "Epoch 125/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 9.9041e-04\n",
      "Epoch 126/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 9.6909e-04\n",
      "Epoch 127/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 9.4754e-04\n",
      "Epoch 128/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 9.2753e-04\n",
      "Epoch 129/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 9.0845e-04\n",
      "Epoch 130/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 9.0032e-04 - val_accuracy: 1.0000 - val_loss: 8.9014e-04\n",
      "Epoch 131/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 8.7340e-04\n",
      "Epoch 132/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 1.0000 - val_loss: 8.5515e-04\n",
      "Epoch 133/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 8.3797e-04\n",
      "Epoch 134/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 4.4541e-04 - val_accuracy: 1.0000 - val_loss: 8.2264e-04\n",
      "Epoch 135/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 8.0819e-04\n",
      "Epoch 136/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 7.9450e-04\n",
      "Epoch 137/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 6.1498e-04 - val_accuracy: 1.0000 - val_loss: 7.8178e-04\n",
      "Epoch 138/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 7.6910e-04\n",
      "Epoch 139/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 8.4027e-04 - val_accuracy: 1.0000 - val_loss: 7.5715e-04\n",
      "Epoch 140/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 7.4518e-04\n",
      "Epoch 141/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 7.3288e-04\n",
      "Epoch 142/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 8.2776e-04 - val_accuracy: 1.0000 - val_loss: 7.2118e-04\n",
      "Epoch 143/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 7.0811e-04\n",
      "Epoch 144/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 9.4280e-04 - val_accuracy: 1.0000 - val_loss: 6.9596e-04\n",
      "Epoch 145/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 6.8002e-04\n",
      "Epoch 146/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 6.4948e-04 - val_accuracy: 1.0000 - val_loss: 6.6621e-04\n",
      "Epoch 147/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 4.2286e-04 - val_accuracy: 1.0000 - val_loss: 6.5429e-04\n",
      "Epoch 148/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 9.6161e-04 - val_accuracy: 1.0000 - val_loss: 6.4313e-04\n",
      "Epoch 149/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 8.3049e-04 - val_accuracy: 1.0000 - val_loss: 6.3273e-04\n",
      "Epoch 150/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 6.2210e-04\n",
      "Epoch 151/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 6.2510e-04 - val_accuracy: 1.0000 - val_loss: 6.1251e-04\n",
      "Epoch 152/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 6.0307e-04\n",
      "Epoch 153/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 6.9007e-04 - val_accuracy: 1.0000 - val_loss: 5.9422e-04\n",
      "Epoch 154/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 5.4953e-04 - val_accuracy: 1.0000 - val_loss: 5.8600e-04\n",
      "Epoch 155/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 5.9864e-04 - val_accuracy: 1.0000 - val_loss: 5.7829e-04\n",
      "Epoch 156/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 5.7078e-04\n",
      "Epoch 157/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 4.0860e-04 - val_accuracy: 1.0000 - val_loss: 5.6348e-04\n",
      "Epoch 158/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 6.5195e-04 - val_accuracy: 1.0000 - val_loss: 5.5666e-04\n",
      "Epoch 159/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 5.4838e-04\n",
      "Epoch 160/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 4.5109e-04 - val_accuracy: 1.0000 - val_loss: 5.4064e-04\n",
      "Epoch 161/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 7.0361e-04 - val_accuracy: 1.0000 - val_loss: 5.3313e-04\n",
      "Epoch 162/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 5.2539e-04\n",
      "Epoch 163/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 5.8519e-04 - val_accuracy: 1.0000 - val_loss: 5.1773e-04\n",
      "Epoch 164/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 5.5109e-04 - val_accuracy: 1.0000 - val_loss: 5.1067e-04\n",
      "Epoch 165/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 9.8764e-04 - val_accuracy: 1.0000 - val_loss: 5.0350e-04\n",
      "Epoch 166/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 5.2379e-04 - val_accuracy: 1.0000 - val_loss: 4.9688e-04\n",
      "Epoch 167/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 9.3234e-04 - val_accuracy: 1.0000 - val_loss: 4.9021e-04\n",
      "Epoch 168/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 4.7253e-04 - val_accuracy: 1.0000 - val_loss: 4.8375e-04\n",
      "Epoch 169/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 4.7746e-04\n",
      "Epoch 170/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 3.9945e-04 - val_accuracy: 1.0000 - val_loss: 4.7133e-04\n",
      "Epoch 171/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 4.6468e-04\n",
      "Epoch 172/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 4.2736e-04 - val_accuracy: 1.0000 - val_loss: 4.5861e-04\n",
      "Epoch 173/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 4.4866e-04 - val_accuracy: 1.0000 - val_loss: 4.5298e-04\n",
      "Epoch 174/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 4.4687e-04\n",
      "Epoch 175/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 3.4095e-04 - val_accuracy: 1.0000 - val_loss: 4.4133e-04\n",
      "Epoch 176/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 8.2682e-04 - val_accuracy: 1.0000 - val_loss: 4.3573e-04\n",
      "Epoch 177/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 5.2644e-04 - val_accuracy: 1.0000 - val_loss: 4.3040e-04\n",
      "Epoch 178/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 6.0795e-04 - val_accuracy: 1.0000 - val_loss: 4.2530e-04\n",
      "Epoch 179/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 7.1092e-04 - val_accuracy: 1.0000 - val_loss: 4.2021e-04\n",
      "Epoch 180/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 4.9605e-04 - val_accuracy: 1.0000 - val_loss: 4.1512e-04\n",
      "Epoch 181/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 8.6815e-04 - val_accuracy: 1.0000 - val_loss: 4.0993e-04\n",
      "Epoch 182/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 6.3955e-04 - val_accuracy: 1.0000 - val_loss: 4.0496e-04\n",
      "Epoch 183/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 6.3396e-04 - val_accuracy: 1.0000 - val_loss: 3.9998e-04\n",
      "Epoch 184/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 3.9456e-04\n",
      "Epoch 185/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 5.7950e-04 - val_accuracy: 1.0000 - val_loss: 3.8950e-04\n",
      "Epoch 186/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 8.4434e-04 - val_accuracy: 1.0000 - val_loss: 3.8407e-04\n",
      "Epoch 187/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 4.9663e-04 - val_accuracy: 1.0000 - val_loss: 3.7910e-04\n",
      "Epoch 188/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 3.7403e-04\n",
      "Epoch 189/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 5.3336e-04 - val_accuracy: 1.0000 - val_loss: 3.6903e-04\n",
      "Epoch 190/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 5.2150e-04 - val_accuracy: 1.0000 - val_loss: 3.6423e-04\n",
      "Epoch 191/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 9.2385e-04 - val_accuracy: 1.0000 - val_loss: 3.5923e-04\n",
      "Epoch 192/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 5.2673e-04 - val_accuracy: 1.0000 - val_loss: 3.5443e-04\n",
      "Epoch 193/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 6.7704e-04 - val_accuracy: 1.0000 - val_loss: 3.4952e-04\n",
      "Epoch 194/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 7.0601e-04 - val_accuracy: 1.0000 - val_loss: 3.4493e-04\n",
      "Epoch 195/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 2.0639e-04 - val_accuracy: 1.0000 - val_loss: 3.4064e-04\n",
      "Epoch 196/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 6.0031e-04 - val_accuracy: 1.0000 - val_loss: 3.3644e-04\n",
      "Epoch 197/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 1.5490e-04 - val_accuracy: 1.0000 - val_loss: 3.3277e-04\n",
      "Epoch 198/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 2.9479e-04 - val_accuracy: 1.0000 - val_loss: 3.2953e-04\n",
      "Epoch 199/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 2.5555e-04 - val_accuracy: 1.0000 - val_loss: 3.2649e-04\n",
      "Epoch 200/200\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 1.0000 - loss: 4.4165e-04 - val_accuracy: 1.0000 - val_loss: 3.2345e-04\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "num_classes = len(np.unique(y_enc))\n",
    "print(\"Number of classes:\", num_classes)\n",
    "\n",
    "def build_lstm_classifier(timesteps, num_features, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Masking(mask_value=0.0, input_shape=(timesteps, num_features)))\n",
    "    model.add(LSTM(64, return_sequences=False))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(32, activation=\"relu\"))\n",
    "    model.add(Dense(num_classes, activation=\"softmax\"))  # classification\n",
    "    model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "T = X_train.shape[1]\n",
    "F = X_train.shape[2]\n",
    "\n",
    "model = build_lstm_classifier(T, F, num_classes)\n",
    "model.summary()\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=20,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=200,\n",
    "    batch_size=2,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c99d7c-dbdc-4c19-9d62-4bbe21e711a1",
   "metadata": {},
   "source": [
    "# Evaluate Model on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71641e87-31fc-4ad6-87ae-1107366f0f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n",
      "Encoded test labels: [0 0 1 1]\n",
      "Encoded preds: [0 0 1 1]\n",
      "Original test labels: [0 0 2 2]\n",
      "Original preds: [0 0 2 2]\n",
      "\n",
      "Test Accuracy: 1.000\n",
      "\n",
      "Classification report (encoded labels):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n",
      "Confusion matrix (encoded labels):\n",
      "[[2 0]\n",
      " [0 2]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predict probabilities then class indices\n",
    "y_proba = model.predict(X_test)\n",
    "y_pred_enc = np.argmax(y_proba, axis=1)\n",
    "\n",
    "# Map back to original labels (0 / 2) if you want\n",
    "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "y_test_orig = np.array([idx_to_class[i] for i in y_test])\n",
    "y_pred_orig = np.array([idx_to_class[i] for i in y_pred_enc])\n",
    "\n",
    "print(\"Encoded test labels:\", y_test)\n",
    "print(\"Encoded preds:\", y_pred_enc)\n",
    "print(\"Original test labels:\", y_test_orig)\n",
    "print(\"Original preds:\", y_pred_orig)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred_enc)\n",
    "print(f\"\\nTest Accuracy: {acc:.3f}\")\n",
    "\n",
    "print(\"\\nClassification report (encoded labels):\")\n",
    "print(classification_report(y_test, y_pred_enc))\n",
    "\n",
    "print(\"Confusion matrix (encoded labels):\")\n",
    "print(confusion_matrix(y_test, y_pred_enc))\n",
    "\n",
    "# Simple confusion matrix heatmap\n",
    "plt.figure(figsize=(4, 4))\n",
    "cm = confusion_matrix(y_test, y_pred_enc)\n",
    "plt.imshow(cm, interpolation='nearest')\n",
    "plt.title(\"Confusion Matrix (Encoded Classes)\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(num_classes)\n",
    "plt.xticks(tick_marks, [f\"Class {i}\" for i in range(num_classes)], rotation=45)\n",
    "plt.yticks(tick_marks, [f\"Class {i}\" for i in range(num_classes)])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dc8379-52ea-46ab-8d75-8ac78a85b2ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf57cee2-0779-4132-a0b3-cc5ef653daa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
